{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('ml-core': conda)",
   "display_name": "Python 3.8.5 64-bit ('ml-core': conda)",
   "metadata": {
    "interpreter": {
     "hash": "708533c255e91d16ac138b4c1bfede906db9b7d196815aaadd6e04778b473e4e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Idea\n",
    "The key idea behind attention is to formulate how much \"attention\" a system pays towards different regions in its input (trys to find correlatinons).\n",
    "Attention origniates from encoder-decoder architectures for NLP tasks, where long sequences need to be processed and references could get lost.\n",
    "The idea of attention is to give the decoder in an encoder-decoder architecture the most relevant context informations.\n",
    "This is done by calculating an attention vector/ matrix also known as context vector.\n",
    "For each decoding step the decoder gets the previous hidden states as well the attention vector as input and therefore knows on what to focus given the encoding sequence.\n",
    "\n",
    "![](sentence-example-attention.png) - [Reference](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#a-family-of-attention-mechanisms)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Improvement\n",
    "\n",
    "In comparison to classic encoder decoder approaches, with attention the model is able to focus on useful parts of the input over longer sequences.\n",
    "The attention weight will tell the model which part of the input should be in focus.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Concept\n",
    "\n",
    "### Definition\n",
    "\n",
    "1. $a^{<t'>}$: activation vector for timestep *t*\n",
    "\n",
    "2. $\\alpha^{<t,t'>}$: amount of *attention* $\\hat{y}^{<t>}$ should pay to $a^{<t'>}$\n",
    "\n",
    "3. $e^{<t,t'>}$: alignment score (aka energy) (can be trained with a single layer feed forward network)\n",
    "\n",
    "4. $c^{<t>}$: context vector as input to the decoder\n",
    "\n",
    "### Calculus\n",
    "\n",
    "1. $a^{<t'>}=(\\overrightarrow{a}^{<t'>},\\overleftarrow{a}^{<t'>})$\n",
    "\n",
    "2. $\\sum_{t'}\\alpha^{<1,t'>}=1$\n",
    "\n",
    "3. $\\alpha^{<t,t'>}=\\frac{\\exp(e^{<t,t'>})}{\\sum_{t'=1}^{Tx}\\exp(e^{<t,t'>})}$ (using Softmax to ensure $\\sum\\alpha=1$)\n",
    "\n",
    "4. $e^{<t,t'>}=g_t(W_ya^{<t>}+b_y)$ (simple linear network - see below scoring functions)\n",
    "\n",
    "5. $c^{<t>}=\\sum_{t'}\\alpha^{<1,t'>}a^{<t>}$\n",
    "\n",
    "![Attention](attention.png) - [Reference](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3)\n",
    "\n",
    "### Scoring Functions\n",
    " \n",
    "![Scoring-functions](scoring-functions.png) - [Reference](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#a-family-of-attention-mechanisms)\n",
    "\n",
    "### Approaches\n",
    "\n",
    "1. Bahdanau et. al (2015)\n",
    "   1. using additive/concat scoring function\n",
    "   2. input to the next decoder step is the concatenation between the output from the previous decoder time step and context vector from the current time step\n",
    "2. Luong et. al (2015)\n",
    "   1. using different scoring functions:\n",
    "      1. additive/concat\n",
    "      2. dot product\n",
    "      3. location-based\n",
    "      4. general\n",
    "   2. input to the next decoder step is the output of a feed-forward neural network which gets the concatenation of the previous decoder time step and context vector from the current time step"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bahdanau(x, hidden, encoder):    \n",
    "\n",
    "    #compute score/ attention energy first\n",
    "    score = torch.tanh(torch.cat(self.linear_hidden(hidden), self.linear_encoder(encoder)))\n",
    "    # vs. Luong\n",
    "    # score = torch.tanh(self.linear(torch.cat(hidden, encoder)))\n",
    "\n",
    "    # mulitply score with weigth matrix\n",
    "    attn_weights = torch.bmm(self.weight, score)\n",
    "\n",
    "    # attention masking | set padded values to neg infinity -> after softmax they will become 0\n",
    "    attn_weights[~pad_mask.unsqueeze(1)] = float('-inf')\n",
    "\n",
    "    attn_weights = self.softmax(attn_weights)\n",
    "\n",
    "    # multiply attention weights with encoder outputs\n",
    "    context = torch.bmm(attn_weights, encoder_outputs)\n",
    "    \n",
    "    # concat hidden states\n",
    "    output = torch.cat((x, context))\n",
    "\n",
    "    # feed concat of input and context into model\n",
    "    output, hidden = self.model(output, hidden)\n",
    "    return output, hidden\n",
    "\n",
    "def luong(x, hidden, encoder, method):\n",
    "\n",
    "    # compute model \"step\" first\n",
    "    output, hidden = self.model(x, hidden)\n",
    "\n",
    "    #compute score/ attention energy\n",
    "    if self.method == \"dot\":\n",
    "      score = torch.bmm(encoder, hidden)\n",
    "    \n",
    "    elif self.method == \"general\":\n",
    "      hidden = self.linear(hidden)\n",
    "      score = torch.bmm(encoder, hidden)\n",
    "    \n",
    "    elif self.method == \"concat\":\n",
    "      out = torch.tanh(self.linear(hidden + encoder))\n",
    "      score = torch.bmm(out, self.weight)\n",
    "\n",
    "    # mulitply energy with weigth matrix\n",
    "    attn_weights = score\n",
    "\n",
    "    # attention masking | set padded values to neg infinity -> after softmax they will become 0\n",
    "    attn_weights[~pad_mask.unsqueeze(1)] = float('-inf')\n",
    "\n",
    "    attn_weights = self.softmax(attn_weights)\n",
    "\n",
    "    # multiply attention weights with encoder outputs\n",
    "    context = torch.bmm(attn_weights, encoder_outputs)\n",
    "    \n",
    "    # concat hidden states and pass through linear projection layer\n",
    "    output = self.linear(torch.cat((output, context)))\n",
    "\n",
    "    # return concat of output and context\n",
    "    return output, hidden\n",
    "\n"
   ]
  },
  {
   "source": [
    "## References\n",
    "\n",
    "1. [Attn: Illustrated Attention](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3)\n",
    "2. [Attention? Attention!](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#a-family-of-attention-mechanisms)\n",
    "3. [Bahdanau et. al, 2015 - Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "4. [Luong et. al, 2015 - Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)\n",
    "5. [Vaswani et. al, 2017 - Attention Is All You Need](https://arxiv.org/abs/1706.03762)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}