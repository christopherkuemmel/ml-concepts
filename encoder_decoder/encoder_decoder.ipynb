{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Encoder Decoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Idea\n",
    "\n",
    "The encoder decoder architecture consists of two parts: the encoder, which maps an input to a condensed vector representation, and the decoder, which reconstructs the intermediate vector to a target reference.\n",
    "First, the encoder will process the whole input (sequence) to create a latent/spatial vector.\n",
    "Then, the decoder will compute the output step by step. \n",
    "There are several applications which either use the full pipeline for inference or just the encoder or decoder part itself.\n",
    "\n",
    "The encoder decoder architecture is often referenced with the neural machine translation task."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Improvement\n",
    "\n",
    "In comparison to sequential networks (RNNs), where different architectures can be applied, the encoder decoder architecture distinct it's computation into two parts.\n",
    "The benefit of this process is, that in theory you can swap either one of the encoder or decoder.\n",
    "Plus, with different methods you can influence the latent space to match your needs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Concept\n",
    "\n",
    "Basic conept of an encoder decoder architecture:\n",
    "\n",
    "![](encoder-decoder.svg) - [Reference](https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html)\n",
    "\n",
    "RNN encoder decoder:\n",
    "\n",
    "![](seq2seq.png) - [Reference](https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb)\n",
    "\n",
    "![](seq2seq2.png) - [Reference](https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## References\n",
    "\n",
    "1. [Understanding Encoder-Decoder ](https://towardsdatascience.com/understanding-encoder-decoder-sequence-to-sequence-model-679e04af4346)\n",
    "2. [Encoder-Decoder](https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html)\n",
    "3. [Pytorch Sequence2Sequence](https://github.com/bentrevett/pytorch-seq2seq)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Examples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}